{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carmen-chan/UTS_ML2019_ID12614246/blob/master/A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJkElHu7eCg5",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Generative Adversarial Nets\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9JZ3EGwhhB8",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "Machine learning is a novel concept that is constantly being studied and addressed due to the potential that it has. Generative adversarial nets are just one model of machine learning which was developed as a solution to certain problems that faced previous models of machine learning.\n",
        "\n",
        "This report review discusses and critiques the paper ‘Generative Adversarial Nets’ written by Goodfellow et al. This report introduces generative adversarial nets which is a new framework that estimates generative models through an adversarial process. The technical quality of the work in this paper is high, however there can be some further development and improvements which are further discussed in this review.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLz5GSCyeLQR",
        "colab_type": "text"
      },
      "source": [
        "# Content\n",
        "This research is about using an adversarial process to estimate generative models. This paper written by Ian J.Goodfellow along with other authors, explores a new procedure for estimating generative models that attempts to resolve the difficulties in deep generative models. This new framework is able to produce specific training algorithms for various models and optimisation algorithm. The main problem with deep generative models as stated in this paper are that it has difficulty approximating the probabilistic computations that arise through maximum likelihood estimation which is one method that can be used to estimate the parameters of a distribution. The deep generative models also have difficulty using the benefits of piecewise linear units. \n",
        "\n",
        "A new generative model, the ‘adversarial nets’ framework was proposed to sidestep these difficulties in the estimation procedure.  This adversarial process was created through pitting a generative network that generates candidates against a discriminatory network which evaluates them. The goal of the generative network is to fool the discriminatory network by producing unique and realistic candidates that the discriminator does not think are synthesised and are part of the true data. Backpropagation is applied in both the generative and discriminatory network so that the generative network produces more realistic images while the discriminatory network becomes better at flagging synthetic images. This framework was able to generate realistic samples after being trained against each other. It was found that the samples generated were competitive with the better generative models studied in other literature.  \n",
        "\n",
        "The end goal of creating this generative adversarial network is demonstrate how deep generative models can bypass the previously stated issues. The adversarial framework therefore gives a solution to the problem brought up earlier where deep generative models were found to have trouble approximating the probabilistic computations that arise through maximum likelihood estimation. This is done through the addition of a discriminatory network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMAFZcNe9e3",
        "colab_type": "text"
      },
      "source": [
        "# Innovation\n",
        "This research work contributes a new methodology in deep learning and machine learning area. It is also compared with existing models and attempts to make improvements to them. Previously there were benefits of piecewise linear units in the generative context that could not be leveraged. However in this special case using a multilayer perceptron and when the discriminative model is a multilayer perceptron, both models can be trained using only backpropagation and dropout algorithms.\n",
        " \n",
        "The research in this paper is innovative as it is attributed to be the first to look at generative adversarial nets in which a discriminative model was applied to a generative model. The ‘novelty’ of this paper is that it introduces a new framework or concept onto a previous model that has run into issues. This framework where an adversary was introduced was then applied to try and bypass the previous issues of deep generative models. The adversarial framework was validated through testing using datasets MNIST, the Toronto Face Database (TFD) , and CIFAR-10 in which generated samples were found to be competitive relative to other good generative models. \n",
        " \n",
        "The adversarial nets framework, as opposed to the Generative Stochastic Network (GSN) does not require a Markov chain for sampling. This framework is new and innovative as adversarial nets are able to leverage piecewise linear units as they do not need feedback loops for generation. This improves the performance of backpropagation but also causes issues when using feedback loops with unbounded activation.\n",
        " \n",
        "The addition of adversarial models to deep directed graphical models, deep undirected graphical models and generative autoencoders gives a new choice to other researchers to choose from depending on the model they need. This depends on the type of training, inference, sampling, evaluating p(x), and model design that the researchers decide they want to implement. Each has their own advantages and disadvantages but it can clearly be seen that adversarial models have few or less roadblocks to their use as a generative model. This paper thus contributes a new model of machine learning. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvKXxveGfGSz",
        "colab_type": "text"
      },
      "source": [
        "# Technical Quality\n",
        "The work in this paper is highly technical. The authors have supported their theory using proofs and algorithms that the minimax game has a global optimum for probability of distribution equals data generating distribution. This is supported through step by step proofing along with explanations. The researchers also performed experiments to validate their framework by applying their adversarial model on datasets which have previously been used by many other machine learning models. This provides us with a result and findings that can be compared to other models to determine if the results are competitive or not. As these models are all using the same databases to learn, their results can be fairly compared to each other to measure the efficiency or accuracy of the machine learning model. \n",
        " \n",
        "The estimation of the dataset was done through fitting a Gaussian Parzen window to samples generated by the generative models and looking at the log-likelihood under the distribution. Although this method used to estimate likelihood is the best method to the authors knowledge, it may not be appropriate for the best outcome as it has been previously determined to have a high variance and is said to not perform well in high dimensional spaces (Goodfellow et al 2014). Therefore, this can lead to poorer quality of results. The samples from the generator net are then compared to already existing generative models which shows that the adversarial model is competitive and can be advantageous when compared to other models.\n",
        " \n",
        "Conclusions were drawn from just three applications of the framework on three different databases. This may be an insufficient sample size to determine that the adversarial framework is at an advantage over other generative models. This can lead to a poorer quality of conclusion due to small sample size. However, it may be sufficient to determine the competence of the framework.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIbF6xbMfJB7",
        "colab_type": "text"
      },
      "source": [
        "# Application and X-Factor\n",
        "The research in this paper was  primarily based on images which is appropriate for the proposed technique. Further developments of the research work such as exploring a more improved method of likelihood estimation as introduced in Breuleux et al. (2011) as the current method has a high variance does not have a high performance in high dimensional spaces. Furthermore, samples from the generator net after training can be revised to make it more competitive than other generative models.\n",
        " \n",
        "A critique to this adversarial model is that both the generative and discriminatory model need to be closely synchronised during training. If the generative model is trained more relative to the discriminatory model then the machine learning will fail to work. This type of model may also not be the most efficient generative model and there is still a lot of work to be done in areas such as improving the efficiency of coordinating both models with each other. \n",
        " \n",
        "I think the work described in this paper would spark an interesting discussion in class as not only does it explain adversarial nets, it also discusses other methods and how they can be used to assist the experiments. I found this work interesting as I have very basic knowledge on machine learning and neural networks, however after studying this paper, I found that not only is there coding in this area but there is a significant amount of maths and proofing. It was also interesting to learn how two models are trained with the ability to estimate the probability of the origin of a sample, whether it was from a training set of a generative model capturing data distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRDTxGOIfMwR",
        "colab_type": "text"
      },
      "source": [
        "# Presentation\n",
        "This paper was overall well structured although I found it quite difficult to read as there were too many abbreviations that I had to keep referring back to what it represented. Especially in the proofing, an improvement that would make it to be read easier is by adding the meaning of each variable used in the formula. The flow of the argument in the paper was well presented as there was some background information on the related work followed by an explanation of adversarial nets which were visualised by graphs, this was then supported with proofs and experiments. The depth of the argument was strong as it was compared to similar works and it highlighted the benefits of adversarial nets compared with other models. More visuals, such as graphs, tables or pictures of results/output can be included to make it easier to understand for those with basic knowledge on this topic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3huurC8Ofcgt",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "Alain, G., Bengio, Y., Yao, L., Yosinski. J., Laufer, E., Zhang, S. & Vincent, P. 2015, ‘GSNs: Generative Stochastic Networks’ vol. 1, pp 1-2 =\n",
        " \n",
        "Breuleux, O., Bengio, Y. & Vincent, P. 2011, ‘Neural Computation’, Quickly Generating Representative Samples from an RBM-Derived Process, vol. 1, pp 1-3 \n",
        " \n",
        "Brownlee, J. 2019, A Gentle Introduction to Generative Adversarial Networks (GANs), viewed 15 August 2019\n",
        "<https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/>\n",
        "\n",
        "Goodfellow, I., Abadie, J., Mirza, M., Xu, B., Farley, D., Ozair, S., Courville, A. & Bengio, Y. 2014, ‘Generative Adversarial Nets’ vol. 1, pp 1-9\n",
        " \n",
        "\n"
      ]
    }
  ]
}